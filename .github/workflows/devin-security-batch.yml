# Devin Security Batch — Child Workflow
#
# This workflow is dispatched by the orchestrator (devin-security-backlog.yml)
# to process a single batch of CodeQL alerts. It:
#   1. Receives a batch of alert IDs as input
#   2. Fetches alert details from the CodeQL API
#   3. Uses a pre-created Devin session (batch mode) OR creates one
#   4. Polls the session until completion (or timeout)
#   5. Creates a PR with the fixes
#   6. Reports results via workflow artifacts
#
# BATCH MODE: When the orchestrator creates Devin sessions in batch (up-front),
# it passes session_id/session_url as inputs. The child skips session creation
# and goes straight to polling. This enables true batch session creation —
# all sessions start working simultaneously instead of sequentially.
#
# DESIGN: Each child workflow = 1 Devin session = 1 batch of alerts = 1 PR.
# This isolation ensures that a failure in one batch doesn't affect others.
# See DESIGN.md "Sub-Workflow Fan-Out Architecture" for full rationale.

name: Devin Security Batch

on:
  workflow_dispatch:
    inputs:
      batch_id:
        description: "Batch number (e.g., 1, 2, 3)"
        required: true
        type: string
      alert_ids:
        description: "Comma-separated CodeQL alert numbers to fix"
        required: true
        type: string
      branch_name:
        description: "Branch name for this batch's fixes"
        required: true
        type: string
      tracking_issue:
        description: "Issue number for cursor state tracking"
        required: false
        type: string
        default: ""
      session_id:
        description: "Pre-created Devin session ID (batch mode — orchestrator creates sessions up-front)"
        required: false
        type: string
        default: ""
      session_url:
        description: "Pre-created Devin session URL (batch mode)"
        required: false
        type: string
        default: ""

permissions:
  contents: write
  security-events: read
  pull-requests: write
  issues: write
  actions: read

env:
  BATCH_ID: ${{ github.event.inputs.batch_id }}
  ALERT_IDS: ${{ github.event.inputs.alert_ids }}
  BRANCH_NAME: ${{ github.event.inputs.branch_name }}
  TRACKING_ISSUE: ${{ github.event.inputs.tracking_issue }}
  PRE_SESSION_ID: ${{ github.event.inputs.session_id }}
  PRE_SESSION_URL: ${{ github.event.inputs.session_url }}

jobs:
  process-batch:
    runs-on: ubuntu-latest
    outputs:
      session_id: ${{ steps.create-session.outputs.session_id }}
      session_url: ${{ steps.create-session.outputs.session_url }}
      session_status: ${{ steps.poll-session.outputs.status }}
      pr_number: ${{ steps.create-pr.outputs.pr_number }}
      pr_url: ${{ steps.create-pr.outputs.pr_url }}
      fixed_count: ${{ steps.collect-results.outputs.fixed_count }}
      failed_count: ${{ steps.collect-results.outputs.failed_count }}
      fixed_alert_ids: ${{ steps.collect-results.outputs.fixed_alert_ids }}
      unfixable_alert_ids: ${{ steps.collect-results.outputs.unfixable_alert_ids }}
      result_json: ${{ steps.collect-results.outputs.result_json }}

    steps:
      - uses: actions/checkout@v4

      # ----------------------------------------------------------------
      # STEP 0: Parse the repo's CodeQL configuration dynamically
      # This makes the workflow portable — it reads the ACTUAL codeql.yml
      # from THIS repo and extracts: languages, query suite, threat models.
      # If no codeql.yml is found, falls back to sensible defaults.
      # ----------------------------------------------------------------
      - name: Parse CodeQL configuration
        id: codeql-config
        run: |
          python3 -u << 'CONFIG_EOF'
          import yaml, json, os, glob

          gh_out = os.environ.get("GITHUB_OUTPUT", "/dev/null")

          # Find the CodeQL workflow file
          codeql_file = None
          for pattern in [".github/workflows/codeql*.yml", ".github/workflows/codeql*.yaml",
                          ".github/workflows/code-scanning*.yml", ".github/workflows/code-scanning*.yaml"]:
              matches = glob.glob(pattern)
              if matches:
                  codeql_file = matches[0]
                  break

          if not codeql_file:
              print("No CodeQL workflow found — using defaults")
              with open(gh_out, "a") as f:
                  f.write("languages=python\n")
                  f.write("query_suite=security-and-quality\n")
                  f.write("threat_models=remote,local\n")
                  f.write("codeql_config_source=defaults\n")
              raise SystemExit(0)

          print(f"Found CodeQL workflow: {codeql_file}")

          with open(codeql_file) as f:
              workflow = yaml.safe_load(f)

          # Extract languages from matrix strategy
          languages = set()
          for job_name, job in workflow.get("jobs", {}).items():
              matrix = job.get("strategy", {}).get("matrix", {})
              # Check matrix.include
              for item in matrix.get("include", []):
                  if "language" in item:
                      languages.add(item["language"])
              # Check matrix.language (direct list)
              lang_list = matrix.get("language", [])
              if isinstance(lang_list, list):
                  languages.update(lang_list)
              elif isinstance(lang_list, str):
                  languages.add(lang_list)

              # Also check steps for codeql-action/init with languages input
              for step in job.get("steps", []):
                  uses = step.get("uses", "")
                  if "codeql-action/init" in uses:
                      with_block = step.get("with", {})
                      langs_str = with_block.get("languages", "")
                      if langs_str and ("$" + "{{") not in str(langs_str):
                          for lang in str(langs_str).split(","):
                              languages.add(lang.strip())

          # Extract query suite and threat models from codeql-action/init
          query_suite = ""
          threat_models = set()
          for job_name, job in workflow.get("jobs", {}).items():
              for step in job.get("steps", []):
                  uses = step.get("uses", "")
                  if "codeql-action/init" in uses:
                      with_block = step.get("with", {})
                      # Query suite
                      queries = with_block.get("queries", "")
                      if queries:
                          query_suite = str(queries)
                      # Threat models from config block
                      config_str = with_block.get("config", "")
                      if config_str:
                          try:
                              config = yaml.safe_load(str(config_str))
                              if isinstance(config, dict):
                                  for tm in config.get("threat-models", []):
                                      threat_models.add(str(tm))
                          except Exception as e:
                              print(f"  Warning: could not parse config block: {e}")

          # Apply defaults for anything not found
          if not languages:
              languages = {"python"}
              print("  No languages found in matrix — defaulting to python")
          if not query_suite:
              query_suite = "security-and-quality"
              print("  No query suite found — defaulting to security-and-quality")
          if not threat_models:
              threat_models = {"remote", "local"}
              print("  No threat models found — defaulting to remote,local")

          languages_str = ",".join(sorted(languages))
          threat_models_str = ",".join(sorted(threat_models))

          print(f"  Languages: {languages_str}")
          print(f"  Query suite: {query_suite}")
          print(f"  Threat models: {threat_models_str}")

          with open(gh_out, "a") as f:
              f.write(f"languages={languages_str}\n")
              f.write(f"query_suite={query_suite}\n")
              f.write(f"threat_models={threat_models_str}\n")
              f.write(f"codeql_config_source={codeql_file}\n")
          CONFIG_EOF

      # ----------------------------------------------------------------
      # STEP 1: Fetch alert details from CodeQL API
      # ----------------------------------------------------------------
      - name: Fetch alert details
        id: fetch-alerts
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
        run: |
          REPO="${{ github.repository }}"
          IFS=',' read -ra IDS <<< "$ALERT_IDS"
          echo "Fetching ${#IDS[@]} alerts for batch $BATCH_ID..."

          echo '[]' > /tmp/batch_alerts.json
          FETCHED=0
          FAILED_FETCH=0

          for ALERT_NUM in "${IDS[@]}"; do
            ALERT_NUM=$(echo "$ALERT_NUM" | tr -d ' ')
            if [ -z "$ALERT_NUM" ]; then
              continue
            fi

            RESP=$(curl -s -L \
              -H "Authorization: token $GH_PAT" \
              -H "Accept: application/vnd.github+json" \
              "https://api.github.com/repos/$REPO/code-scanning/alerts/$ALERT_NUM")

            STATE=$(echo "$RESP" | jq -r '.state // "unknown"')
            if [ "$STATE" = "open" ]; then
              jq --argjson alert "$RESP" '. + [$alert]' /tmp/batch_alerts.json > /tmp/batch_alerts_tmp.json
              mv /tmp/batch_alerts_tmp.json /tmp/batch_alerts.json
              FETCHED=$((FETCHED + 1))
            else
              echo "Alert #$ALERT_NUM state=$STATE (skipping — may already be fixed)"
              FAILED_FETCH=$((FAILED_FETCH + 1))
            fi
          done

          echo "Fetched $FETCHED open alerts ($FAILED_FETCH skipped)"
          echo "alert_count=$FETCHED" >> $GITHUB_OUTPUT

          if [ "$FETCHED" -eq 0 ]; then
            echo "::warning::No open alerts found for batch $BATCH_ID. All may have been fixed already."
            echo "skip=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          echo "skip=false" >> $GITHUB_OUTPUT

          # Build alert summary for Devin prompt
          python3 << 'SUMMARY_EOF'
          import json

          with open("/tmp/batch_alerts.json") as f:
              alerts = json.load(f)

          summary_lines = []
          details = []
          for a in alerts:
              rule_id = a.get("rule", {}).get("id", "unknown")
              desc = a.get("rule", {}).get("description", rule_id)
              loc = a.get("most_recent_instance", {}).get("location", {})
              path = loc.get("path", "unknown")
              line = loc.get("start_line", 0)
              severity = a.get("rule", {}).get("security_severity_level", "unknown")
              message = a.get("most_recent_instance", {}).get("message", {}).get("text", "")

              summary_lines.append(f"- [{rule_id}] {desc} at {path}:{line} (severity: {severity})")
              details.append({
                  "number": a.get("number"),
                  "rule_id": rule_id,
                  "rule_description": desc,
                  "severity": severity,
                  "file": path,
                  "start_line": line,
                  "end_line": loc.get("end_line", line),
                  "message": message,
                  "key": f"{rule_id}:{path}:{line}"
              })

          with open("/tmp/batch_summary.txt", "w") as f:
              f.write("\n".join(summary_lines))
          with open("/tmp/batch_details.json", "w") as f:
              json.dump(details, f, indent=2)

          print(f"Prepared {len(details)} alerts for Devin session")
          for s in summary_lines:
              print(f"  {s}")
          SUMMARY_EOF

      # ----------------------------------------------------------------
      # STEP 2: Create Devin session for this batch (or use pre-created)
      #
      # BATCH MODE: If the orchestrator created the session up-front and
      # passed session_id as input, we skip creation and go straight to
      # polling. This enables true batch session creation — all sessions
      # in a wave start working simultaneously instead of sequentially.
      #
      # STANDALONE MODE: If no session_id is provided (manual dispatch),
      # we create the session here as before.
      # ----------------------------------------------------------------
      - name: Create Devin session
        id: create-session
        if: steps.fetch-alerts.outputs.skip != 'true'
        env:
          DEVIN_API_KEY: ${{ secrets.DEVIN_API_KEY }}
          CODEQL_LANGUAGES: ${{ steps.codeql-config.outputs.languages }}
          CODEQL_QUERY_SUITE: ${{ steps.codeql-config.outputs.query_suite }}
          CODEQL_THREAT_MODELS: ${{ steps.codeql-config.outputs.threat_models }}
          CODEQL_CONFIG_SOURCE: ${{ steps.codeql-config.outputs.codeql_config_source }}
        run: |
          # ── BATCH MODE: Use pre-created session from orchestrator ──
          if [ -n "$PRE_SESSION_ID" ]; then
            echo "=== BATCH MODE: Using pre-created session ==="
            echo "Session ID: $PRE_SESSION_ID"
            echo "Session URL: $PRE_SESSION_URL"
            echo "session_id=$PRE_SESSION_ID" >> $GITHUB_OUTPUT
            echo "session_url=$PRE_SESSION_URL" >> $GITHUB_OUTPUT
            echo "session_created=true" >> $GITHUB_OUTPUT
            echo "batch_mode=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          # ── STANDALONE MODE: Create session here ──
          echo "=== STANDALONE MODE: Creating new Devin session ==="

          REPO="${{ github.repository }}"
          ALERT_SUMMARY=$(cat /tmp/batch_summary.txt)
          ALERT_DETAILS=$(cat /tmp/batch_details.json)

          PRIMARY_LANG=$(echo "$CODEQL_LANGUAGES" | cut -d',' -f1)
          QUERY_PACK="codeql/${PRIMARY_LANG}-queries:codeql-suites/${PRIMARY_LANG}-${CODEQL_QUERY_SUITE}.qls"

          THREAT_FLAGS=""
          THREAT_DISPLAY=""
          IFS=',' read -ra TM_ARRAY <<< "$CODEQL_THREAT_MODELS"
          for tm in "${TM_ARRAY[@]}"; do
            THREAT_DISPLAY="${THREAT_DISPLAY:+$THREAT_DISPLAY AND }$tm"
            if [ "$tm" != "remote" ]; then
              THREAT_FLAGS="${THREAT_FLAGS} --threat-model=$tm"
            fi
          done

          PROMPT=$(cat <<PROMPT_EOF
          CRITICAL OPERATING MODE: You are running inside an UNATTENDED CI/CD pipeline with NO human operator. You MUST NOT use block_on_user=true, you MUST NOT ask questions, you MUST NOT wait for confirmation, you MUST NOT request approval. If you encounter ANY uncertainty, make your best judgment and continue. If you get stuck, skip the current alert and move to the next one. NEVER stop working to wait for input.

          You are a security engineer fixing pre-existing CodeQL vulnerabilities in repository ${REPO}.

          This is Batch #${BATCH_ID} of an automated backlog sweep. Fix these alerts on a new branch.

          Alerts to fix:

          ${ALERT_SUMMARY}

          Detailed alert information:
          ${ALERT_DETAILS}

          Instructions:
          1. Clone the repository: https://github.com/${REPO}.git
          2. Create and checkout branch '${BRANCH_NAME}' from main
          3. For each alert, read the surrounding code and understand the full context
          4. Fix each alert ONE AT A TIME. For each alert:
             a. Apply a minimal, focused fix following the codebase's existing conventions
             b. VERIFY the fix locally by running CodeQL CLI to confirm the alert is resolved.
                IMPORTANT: You MUST use the EXACT same CodeQL configuration as the repo's CI.
                This repo's CI config (parsed from ${CODEQL_CONFIG_SOURCE}) uses:
                  - languages: ${CODEQL_LANGUAGES}
                  - queries: ${CODEQL_QUERY_SUITE}
                  - threat-models: ${THREAT_DISPLAY}
                Your verification commands:
                - Download and extract CodeQL CLI (only once, reuse for all alerts):
                  wget -q https://github.com/github/codeql-cli-binaries/releases/latest/download/codeql-linux64.zip && unzip -qo codeql-linux64.zip
                - Create a fresh database (MUST use --overwrite since DB may exist from prior alert):
                  ./codeql/codeql database create /tmp/codeql-db --language=${PRIMARY_LANG} --source-root=. --overwrite
                - Run analysis with the EXACT same query suite and threat models as CI:
                  ./codeql/codeql database analyze /tmp/codeql-db ${QUERY_PACK} --format=sarif-latest --output=/tmp/results.sarif --download${THREAT_FLAGS}
                - Parse the SARIF output to check for ANY alerts in the file you modified (not just the specific rule — your fix must not introduce NEW alerts):
                  python3 -c "import json; sarif=json.load(open('/tmp/results.sarif')); results=[r for run in sarif['runs'] for r in run.get('results',[])]; file_alerts=[r for r in results if any(loc.get('physicalLocation',{}).get('artifactLocation',{}).get('uri','').endswith('FILE') for loc in r.get('locations',[]))]; print(f'Found {len(file_alerts)} alerts in FILE'); [print(f'  - {r["ruleId"]}:{r.get("message",{}).get("text","")[:80]}') for r in file_alerts]; exit(1 if file_alerts else 0)"
                  (Replace FILE with the actual file path for each alert)
             c. If ANY alert (old or new) still appears in the file after your fix, revise your approach and re-run CodeQL (max 2 attempts total)
             d. If after 2 attempts alerts persist, SKIP this alert entirely — do NOT commit a broken fix. Note it as unfixable and move on immediately.
             e. If the file is clean (CodeQL reports zero alerts for it), commit with message: fix: [rule_id] description (file:line)
          5. Conventions to follow:
             - If the project uses an ORM, use parameterized queries via the ORM
             - If there are existing sanitization utilities, reuse them
             - Do not introduce new dependencies unless absolutely necessary
          6. If the repository has tests, run them to ensure no regressions
          7. Push all commit(s) to branch '${BRANCH_NAME}'
          8. After processing ALL alerts, finish your session immediately. Do not wait.

          IMPORTANT RULES — VIOLATION WILL BREAK THE PIPELINE:
          - NEVER use block_on_user=true. NEVER ask questions. NEVER wait for input. This is fully automated.
          - If you are unsure about ANYTHING, make your best judgment and continue. Do not stop.
          - Each security issue MUST be a separate commit
          - Do NOT just suppress or ignore alerts — fix the root cause
          - Keep fixes minimal and surgical — do not refactor unrelated code
          - If an alert cannot be fixed after 2 CodeQL verification attempts, SKIP it immediately
          - Your fixes will be verified by the pipeline using the EXACT same CodeQL config as CI. If your fix introduces new alerts or does not resolve the target, the PR will be flagged.
          - When done with all alerts, push your branch and end the session. Do not block.
          PROMPT_EOF
          )

          PROMPT_JSON=$(echo "$PROMPT" | python3 -c "import sys,json; print(json.dumps(sys.stdin.read()))")

          RESPONSE=$(curl -s -w "\n%{http_code}" \
            -X POST "https://api.devin.ai/v1/sessions" \
            -H "Authorization: Bearer $DEVIN_API_KEY" \
            -H "Content-Type: application/json" \
            -d "{\"prompt\": $PROMPT_JSON, \"max_acu_limit\": 10}")

          HTTP_CODE=$(echo "$RESPONSE" | tail -1)
          BODY=$(echo "$RESPONSE" | head -n -1)

          echo "Devin API response (HTTP $HTTP_CODE):"
          echo "$BODY" | jq . 2>/dev/null || echo "$BODY"

          RETRY_WAIT=60
          RETRY_COUNT=0
          MAX_RETRIES=3
          while [ "$HTTP_CODE" = "429" ] && [ "$RETRY_COUNT" -lt "$MAX_RETRIES" ]; do
            RETRY_COUNT=$((RETRY_COUNT + 1))
            echo "Rate limited (429). Retry ${RETRY_COUNT}/${MAX_RETRIES} — waiting ${RETRY_WAIT}s..."
            sleep $RETRY_WAIT
            RESPONSE=$(curl -s -w "\n%{http_code}" \
              -X POST "https://api.devin.ai/v1/sessions" \
              -H "Authorization: Bearer $DEVIN_API_KEY" \
              -H "Content-Type: application/json" \
              -d "{\"prompt\": $PROMPT_JSON, \"max_acu_limit\": 10}")
            HTTP_CODE=$(echo "$RESPONSE" | tail -1)
            BODY=$(echo "$RESPONSE" | head -n -1)
            echo "Retry ${RETRY_COUNT} response (HTTP $HTTP_CODE):"
            echo "$BODY" | jq . 2>/dev/null || echo "$BODY"
            RETRY_WAIT=$((RETRY_WAIT * 2))
          done

          SESSION_ID=$(echo "$BODY" | jq -r '.session_id // empty')
          SESSION_URL=$(echo "$BODY" | jq -r '.url // empty')
          if [ -z "$SESSION_URL" ] && [ -n "$SESSION_ID" ]; then
            SESSION_URL="https://app.devin.ai/sessions/${SESSION_ID}"
          fi

          if [ -z "$SESSION_ID" ]; then
            echo "::error::Failed to create Devin session for batch $BATCH_ID (HTTP $HTTP_CODE)"
            echo "session_created=false" >> $GITHUB_OUTPUT
            echo "session_id=" >> $GITHUB_OUTPUT
            echo "session_url=" >> $GITHUB_OUTPUT
            exit 1
          fi

          echo "Devin session created: $SESSION_URL"
          echo "session_id=$SESSION_ID" >> $GITHUB_OUTPUT
          echo "session_url=$SESSION_URL" >> $GITHUB_OUTPUT
          echo "session_created=true" >> $GITHUB_OUTPUT
          echo "batch_mode=false" >> $GITHUB_OUTPUT

      # ----------------------------------------------------------------
      # STEP 3: Poll Devin session until completion
      # Polls every 60s, timeout after 45 minutes (45 polls)
      # ----------------------------------------------------------------
      - name: Poll Devin session status
        id: poll-session
        if: steps.create-session.outputs.session_created == 'true'
        env:
          DEVIN_API_KEY: ${{ secrets.DEVIN_API_KEY }}
          SESSION_ID: ${{ steps.create-session.outputs.session_id }}
        run: |
          # Bug #43 fix: Per Devin API docs, "blocked" and "finished" are BOTH
          # terminal states. The official polling example treats them equivalently:
          #   if status_enum in ["blocked", "finished"]: return results
          # Sessions go "blocked" when Devin completes its work and sends a final
          # message with block_on_user=true. This is normal completion behavior,
          # NOT an error. Previous unblock attempts (Bugs #34, #37, #41) wasted
          # ~13 min per batch fighting against this designed behavior.
          MAX_POLLS=45
          POLL_INTERVAL=60
          POLL=0

          echo "Polling session $SESSION_ID every ${POLL_INTERVAL}s (max ${MAX_POLLS} polls = $(( MAX_POLLS * POLL_INTERVAL / 60 )) min)..."

          while [ $POLL -lt $MAX_POLLS ]; do
            POLL=$((POLL + 1))

              RESP=$(curl -s \
                -H "Authorization: Bearer $DEVIN_API_KEY" \
                "https://api.devin.ai/v1/sessions/$SESSION_ID")

              if ! echo "$RESP" | jq empty 2>/dev/null; then
                echo "Poll $POLL/$MAX_POLLS: API returned non-JSON response (${#RESP} bytes). Retrying..."
                if [ $POLL -lt $MAX_POLLS ]; then
                  sleep $POLL_INTERVAL
                fi
                continue
              fi

              STATUS=$(echo "$RESP" | jq -r '.status // "unknown"')
              STATUS_ENUM=$(echo "$RESP" | jq -r '.status_enum // "unknown"')
              echo "Poll $POLL/$MAX_POLLS: status=$STATUS status_enum=$STATUS_ENUM"

              EFFECTIVE_STATUS="$STATUS_ENUM"
              if [ "$EFFECTIVE_STATUS" = "unknown" ] || [ "$EFFECTIVE_STATUS" = "null" ]; then
                EFFECTIVE_STATUS="$STATUS"
              fi

              case "$EFFECTIVE_STATUS" in
                finished|stopped|blocked)
                  echo "Session reached terminal state: status=$STATUS status_enum=$STATUS_ENUM"
                  echo "status=$EFFECTIVE_STATUS" >> $GITHUB_OUTPUT
                  echo "completed=true" >> $GITHUB_OUTPUT
                  exit 0
                  ;;
                expired)
                  echo "::warning::Session expired (status=$STATUS status_enum=$STATUS_ENUM)"
                  echo "status=expired" >> $GITHUB_OUTPUT
                  echo "completed=true" >> $GITHUB_OUTPUT
                  exit 0
                  ;;
                suspended|suspend_requested|suspend_requested_frontend)
                  echo "::warning::Session is $EFFECTIVE_STATUS — may need manual intervention"
                  echo "status=$EFFECTIVE_STATUS" >> $GITHUB_OUTPUT
                  echo "completed=true" >> $GITHUB_OUTPUT
                  exit 0
                  ;;
                failed|error)
                  echo "::error::Session failed with status=$STATUS status_enum=$STATUS_ENUM"
                  echo "status=failed" >> $GITHUB_OUTPUT
                  echo "completed=true" >> $GITHUB_OUTPUT
                  exit 0
                  ;;
              esac

            if [ $POLL -lt $MAX_POLLS ]; then
              sleep $POLL_INTERVAL
            fi
          done

          echo "::warning::Session polling timed out after $(( MAX_POLLS * POLL_INTERVAL / 60 )) minutes"
          echo "status=timeout" >> $GITHUB_OUTPUT
          echo "completed=false" >> $GITHUB_OUTPUT

      # ----------------------------------------------------------------
      # STEP 3b: Verify fixes with CodeQL (Bug #42 fix)
      # After Devin pushes fixes, run CodeQL locally with the EXACT same
      # configuration as CI to verify fixes before creating the PR.
      # This catches: (1) fixes that don't resolve the target alert,
      # (2) new alerts introduced by the fix (e.g., unused imports),
      # (3) config mismatches between Devin's internal check and CI.
      # ----------------------------------------------------------------
      - name: Verify fixes with CodeQL
        id: verify-codeql
        if: steps.poll-session.outputs.status == 'finished' || steps.poll-session.outputs.status == 'blocked' || steps.poll-session.outputs.status == 'stopped'
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
          CODEQL_LANGUAGES: ${{ steps.codeql-config.outputs.languages }}
          CODEQL_QUERY_SUITE: ${{ steps.codeql-config.outputs.query_suite }}
          CODEQL_THREAT_MODELS: ${{ steps.codeql-config.outputs.threat_models }}
          CODEQL_CONFIG_SOURCE: ${{ steps.codeql-config.outputs.codeql_config_source }}
        run: |
          REPO="${{ github.repository }}"

          # Check if branch exists first
          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" \
            -H "Authorization: token $GH_PAT" \
            "https://api.github.com/repos/$REPO/branches/$BRANCH_NAME")

          if [ "$HTTP_CODE" != "200" ]; then
            echo "Branch $BRANCH_NAME not found — skipping CodeQL verification"
            echo "verified=skip" >> $GITHUB_OUTPUT
            echo "new_alerts=0" >> $GITHUB_OUTPUT
            echo "remaining_alerts=0" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "=== CodeQL Verification (Bug #42 fix) ==="
          echo "Config source: $CODEQL_CONFIG_SOURCE"
          echo "Languages: $CODEQL_LANGUAGES"
          echo "Query suite: $CODEQL_QUERY_SUITE"
          echo "Threat models: $CODEQL_THREAT_MODELS"
          echo "Checking out branch $BRANCH_NAME for local CodeQL analysis..."

          # Fetch and checkout the branch Devin pushed to
          git fetch origin "$BRANCH_NAME"
          git checkout "$BRANCH_NAME"

          # Install CodeQL CLI
          echo "Downloading CodeQL CLI..."
          wget -q https://github.com/github/codeql-cli-binaries/releases/latest/download/codeql-linux64.zip
          unzip -qo codeql-linux64.zip

          # Build dynamic commands from parsed repo config
          PRIMARY_LANG=$(echo "$CODEQL_LANGUAGES" | cut -d',' -f1)
          QUERY_PACK="codeql/${PRIMARY_LANG}-queries:codeql-suites/${PRIMARY_LANG}-${CODEQL_QUERY_SUITE}.qls"

          # Build threat model flags
          THREAT_FLAGS=""
          IFS=',' read -ra TM_ARRAY <<< "$CODEQL_THREAT_MODELS"
          for tm in "${TM_ARRAY[@]}"; do
            if [ "$tm" != "remote" ]; then
              THREAT_FLAGS="${THREAT_FLAGS} --threat-model=$tm"
            fi
          done

          echo "Creating CodeQL database (language=$PRIMARY_LANG)..."
          ./codeql/codeql database create /tmp/codeql-verify-db \
            --language=$PRIMARY_LANG \
            --source-root=. \
            --overwrite \
            2>&1 || true

          echo "Running CodeQL analysis ($QUERY_PACK, threat flags:$THREAT_FLAGS)..."
          ./codeql/codeql database analyze /tmp/codeql-verify-db \
            $QUERY_PACK \
            --format=sarif-latest \
            --output=/tmp/verify-results.sarif \
            --download \
            $THREAT_FLAGS \
            2>&1 || true

          # Parse results
          if [ ! -f /tmp/verify-results.sarif ]; then
            echo "::warning::CodeQL verification could not produce SARIF output"
            echo "verified=error" >> $GITHUB_OUTPUT
            echo "new_alerts=0" >> $GITHUB_OUTPUT
            echo "remaining_alerts=0" >> $GITHUB_OUTPUT
            git checkout main 2>/dev/null || true
            exit 0
          fi

          python3 -u << 'VERIFY_EOF'
          import json, os

          with open("/tmp/verify-results.sarif") as f:
              sarif = json.load(f)

          with open("/tmp/batch_details.json") as f:
              batch_alerts = json.load(f)

          target_files = set()
          target_keys = set()
          for a in batch_alerts:
              f = a.get("file", "")
              target_files.add(f)
              target_keys.add(f"{a['rule_id']}:{f}:{a['start_line']}")

          all_results = []
          for run in sarif.get("runs", []):
              for result in run.get("results", []):
                  rule_id = result.get("ruleId", "")
                  for loc in result.get("locations", []):
                      phys = loc.get("physicalLocation", {})
                      uri = phys.get("artifactLocation", {}).get("uri", "")
                      line = phys.get("region", {}).get("startLine", 0)
                      all_results.append({
                          "rule_id": rule_id,
                          "file": uri,
                          "line": line,
                          "message": result.get("message", {}).get("text", "")[:100]
                      })

          remaining = []
          for r in all_results:
              key = f"{r['rule_id']}:{r['file']}:{r['line']}"
              if key in target_keys:
                  remaining.append(r)

          new_alerts = []
          for r in all_results:
              if r["file"] in target_files:
                  key = f"{r['rule_id']}:{r['file']}:{r['line']}"
                  if key not in target_keys:
                      new_alerts.append(r)

          print(f"\n=== CodeQL Verification Results ===")
          print(f"Total SARIF results: {len(all_results)}")
          print(f"Target alerts still present: {len(remaining)}")
          print(f"New alerts in modified files: {len(new_alerts)}")

          if remaining:
              print(f"\nREMAINING target alerts (fix did not resolve):")
              for r in remaining:
                  print(f"  - [{r['rule_id']}] {r['file']}:{r['line']}")
          if new_alerts:
              print(f"\nNEW alerts introduced by fix:")
              for r in new_alerts:
                  print(f"  - [{r['rule_id']}] {r['file']}:{r['line']} — {r['message']}")

          verified = "pass" if not remaining and not new_alerts else "fail"
          print(f"\nVerification: {verified.upper()}")

          gh_out = os.environ.get("GITHUB_OUTPUT", "/dev/null")
          with open(gh_out, "a") as f:
              f.write(f"verified={verified}\n")
              f.write(f"remaining_alerts={len(remaining)}\n")
              f.write(f"new_alerts={len(new_alerts)}\n")
              f.write(f"total_sarif_results={len(all_results)}\n")

          verification = {
              "verified": verified,
              "remaining": remaining,
              "new_alerts": new_alerts,
              "total_results": len(all_results)
          }
          with open("/tmp/codeql_verification.json", "w") as f:
              json.dump(verification, f, indent=2)
          VERIFY_EOF

          # Switch back to main for subsequent steps
          git checkout main 2>/dev/null || true

      # ----------------------------------------------------------------
      # STEP 4: Check if the branch exists and create PR
      # ----------------------------------------------------------------
      - name: Create PR for batch fixes
        id: create-pr
        if: steps.poll-session.outputs.status == 'finished' || steps.poll-session.outputs.status == 'stopped' || steps.poll-session.outputs.status == 'suspended' || steps.poll-session.outputs.status == 'suspend_requested' || steps.poll-session.outputs.status == 'suspend_requested_frontend' || steps.poll-session.outputs.status == 'expired' || steps.poll-session.outputs.status == 'blocked'
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
        run: |
          REPO="${{ github.repository }}"
          ALERT_COUNT=$(cat /tmp/batch_details.json | jq 'length')

          # Check if branch exists
          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" \
            -H "Authorization: token $GH_PAT" \
            "https://api.github.com/repos/$REPO/branches/$BRANCH_NAME")

          if [ "$HTTP_CODE" != "200" ]; then
            echo "::warning::Branch $BRANCH_NAME not found (HTTP $HTTP_CODE). Devin may not have pushed fixes."
            echo "pr_created=false" >> $GITHUB_OUTPUT
            echo "pr_number=" >> $GITHUB_OUTPUT
            echo "pr_url=" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "Branch $BRANCH_NAME exists. Creating PR..."

          # Build alert table for PR body
          ALERT_TABLE=$(python3 << 'TABLE_EOF'
          import json

          with open("/tmp/batch_details.json") as f:
              alerts = json.load(f)

          lines = ["| Severity | Rule | File | Line |", "|----------|------|------|------|"]
          for a in alerts:
              lines.append(f"| {a['severity']} | `{a['rule_id']}` | `{a['file']}` | {a['start_line']} |")
          print("\n".join(lines))
          TABLE_EOF
          )

          SESSION_URL="${{ steps.create-session.outputs.session_url }}"

          # Build CodeQL verification section for PR body
          VERIFY_STATUS="${{ steps.verify-codeql.outputs.verified }}"
          VERIFY_REMAINING="${{ steps.verify-codeql.outputs.remaining_alerts }}"
          VERIFY_NEW="${{ steps.verify-codeql.outputs.new_alerts }}"
          if [ "$VERIFY_STATUS" = "pass" ]; then
            VERIFY_SECTION="### CodeQL Verification: PASSED\n- Post-session CodeQL analysis confirmed all target alerts resolved\n- No new alerts introduced by fixes"
          elif [ "$VERIFY_STATUS" = "fail" ]; then
            VERIFY_SECTION="### CodeQL Verification: FAILED\n- Remaining unresolved alerts: ${VERIFY_REMAINING}\n- New alerts introduced by fixes: ${VERIFY_NEW}\n\n> **Action required**: Review fixes carefully — CodeQL verification detected issues."
          elif [ "$VERIFY_STATUS" = "skip" ]; then
            VERIFY_SECTION="### CodeQL Verification: SKIPPED\n- Branch not found — Devin may not have pushed fixes"
          else
            VERIFY_SECTION="### CodeQL Verification: NOT RUN\n- Verification step did not execute (session may have failed)"
          fi

          PR_BODY=$(cat <<PR_BODY_EOF
          ## Security Batch Fix #${BATCH_ID}

          Automated security fixes for ${ALERT_COUNT} CodeQL alert(s) processed by [Devin AI](${SESSION_URL}).

          ### Alerts Addressed

          ${ALERT_TABLE}

          $(echo -e "$VERIFY_SECTION")

          ### Process
          - Each alert was fixed individually with a separate commit
          - Fixes verified internally by Devin using CodeQL CLI (security-and-quality, threat-models: remote+local)
          - Post-session CodeQL verification gate run by pipeline before PR creation
          - Alerts that could not be fixed after 2 attempts were skipped

          ---
          *Generated by [Devin Security Backlog Sweep](https://github.com/${REPO}/actions/runs/${{ github.run_id }})*
          PR_BODY_EOF
          )

          # Get primary files for PR title
          PRIMARY_FILES=$(cat /tmp/batch_details.json | jq -r '[.[].file] | unique | join(", ")' | head -c 80)

          PR_BODY_JSON=$(echo "$PR_BODY" | python3 -c "import sys,json; print(json.dumps(sys.stdin.read()))")

          RESP=$(curl -s -L \
            -X POST \
            -H "Authorization: token $GH_PAT" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/repos/$REPO/pulls" \
            -d "{
              \"title\": \"fix(security): Batch ${BATCH_ID} — ${ALERT_COUNT} CodeQL alerts in ${PRIMARY_FILES}\",
              \"body\": $PR_BODY_JSON,
              \"head\": \"$BRANCH_NAME\",
              \"base\": \"main\"
            }")

          PR_NUMBER=$(echo "$RESP" | jq -r '.number // empty')
          PR_URL=$(echo "$RESP" | jq -r '.html_url // empty')

          if [ -z "$PR_NUMBER" ]; then
            EXISTING=$(curl -s -L \
              -H "Authorization: token $GH_PAT" \
              "https://api.github.com/repos/$REPO/pulls?head=${{ github.repository_owner }}:$BRANCH_NAME&state=open")
            PR_NUMBER=$(echo "$EXISTING" | jq -r '.[0].number // empty')
            PR_URL=$(echo "$EXISTING" | jq -r '.[0].html_url // empty')
            if [ -n "$PR_NUMBER" ]; then
              echo "PR already exists: $PR_URL"
              echo "Updating PR body with structured batch metadata..."
              UPDATE_RESP=$(curl -s -L \
                -X PATCH \
                -H "Authorization: token $GH_PAT" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/repos/$REPO/pulls/$PR_NUMBER" \
                -d "{
                  \"title\": \"fix(security): Batch ${BATCH_ID} — ${ALERT_COUNT} CodeQL alerts in ${PRIMARY_FILES}\",
                  \"body\": $PR_BODY_JSON
                }")
              UPDATE_OK=$(echo "$UPDATE_RESP" | jq -r '.number // empty')
              if [ -n "$UPDATE_OK" ]; then
                echo "PR body updated with structured batch metadata"
              else
                echo "::warning::Could not update PR body (non-critical)"
              fi
            else
              echo "::warning::Failed to create PR for batch $BATCH_ID"
              echo "$RESP" | jq . 2>/dev/null || echo "$RESP"
              echo "pr_created=false" >> $GITHUB_OUTPUT
              exit 0
            fi
          fi

          echo "PR created: $PR_URL"
          echo "pr_number=$PR_NUMBER" >> $GITHUB_OUTPUT
          echo "pr_url=$PR_URL" >> $GITHUB_OUTPUT
          echo "pr_created=true" >> $GITHUB_OUTPUT

          # Add label based on CodeQL verification result
          VERIFY_STATUS="${{ steps.verify-codeql.outputs.verified }}"
          if [ -n "$VERIFY_STATUS" ] && [ "$VERIFY_STATUS" != "skip" ] && [ -n "$PR_NUMBER" ]; then
            if [ "$VERIFY_STATUS" = "pass" ]; then
              LABEL="codeql-verified"
              LABEL_COLOR="0e8a16"
              LABEL_DESC="CodeQL post-session verification passed"
            else
              LABEL="codeql-verification-failed"
              LABEL_COLOR="d93f0b"
              LABEL_DESC="CodeQL post-session verification found issues"
            fi
            # Create label if it doesn't exist
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" \
              -H "Authorization: token $GH_PAT" \
              "https://api.github.com/repos/$REPO/labels/$LABEL")
            if [ "$HTTP_CODE" = "404" ]; then
              curl -s -L -X POST \
                -H "Authorization: token $GH_PAT" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/repos/$REPO/labels" \
                -d "{\"name\":\"$LABEL\",\"color\":\"$LABEL_COLOR\",\"description\":\"$LABEL_DESC\"}" > /dev/null 2>&1 || true
            fi
            # Apply label to PR
            curl -s -L -X POST \
              -H "Authorization: token $GH_PAT" \
              -H "Accept: application/vnd.github+json" \
              "https://api.github.com/repos/$REPO/issues/$PR_NUMBER/labels" \
              -d "{\"labels\":[\"$LABEL\"]}" > /dev/null 2>&1 || true
            echo "Applied label '$LABEL' to PR #$PR_NUMBER"
          fi

      # ----------------------------------------------------------------
      # STEP 5: Collect results and upload artifact
      # ----------------------------------------------------------------
      - name: Collect results
        id: collect-results
        if: always()
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
          REPO: ${{ github.repository }}
          SESSION_STATUS: ${{ steps.poll-session.outputs.status }}
          PR_NUMBER: ${{ steps.create-pr.outputs.pr_number }}
          PR_URL: ${{ steps.create-pr.outputs.pr_url }}
          SESSION_URL: ${{ steps.create-session.outputs.session_url }}
          SESSION_ID: ${{ steps.create-session.outputs.session_id }}
        run: |
          # Determine which specific alerts were fixed vs unfixable.
          #
          # Bug #18 fix: We cannot rely on querying CodeQL alert state on main
          # because the fix is on a PR branch (not yet merged). All alerts will
          # show state=open on main, leading to ALL being marked unfixable.
          #
          # Instead, we use a two-tier approach:
          # 1. Check which files were modified in the branch vs main (file-modification heuristic)
          # 2. For modified files: mark alerts as "attempted" (likely fixed, pending PR merge)
          # 3. For unmodified files: mark alerts as "unfixable" (Devin didn't touch them)
          # 4. Also check CodeQL — if an alert IS already fixed on main, mark it fixed
          #
          # The definitive fixed/unfixable determination happens on subsequent
          # orchestrator runs after the PR is merged and CodeQL re-runs on main.
          python3 << 'RESULT_EOF'
          import json, os, sys, subprocess, time, urllib.request, urllib.error

          sys.stdout.reconfigure(line_buffering=True)
          HTTP_TIMEOUT = 30

          repo = os.environ.get("REPO", "")
          gh_pat = os.environ.get("GH_PAT", "")
          session_status = os.environ.get("SESSION_STATUS", "")
          session_id = os.environ.get("SESSION_ID", "")
          session_url = os.environ.get("SESSION_URL", "")
          pr_number = os.environ.get("PR_NUMBER", "")
          pr_url = os.environ.get("PR_URL", "")
          branch_name = os.environ.get("BRANCH_NAME", "")
          batch_id = os.environ.get("BATCH_ID", "")
          alert_ids_str = os.environ.get("ALERT_IDS", "")

          batch_alert_ids = [int(x.strip()) for x in alert_ids_str.split(",") if x.strip()]
          total = len(batch_alert_ids)

          fixed_ids = []
          attempted_ids = []
          unfixable_ids = []

          headers = {
              "Authorization": f"token {gh_pat}",
              "Accept": "application/vnd.github+json"
          }

          print(f"Session status: {session_status}, branch: {branch_name}")

          if session_status in ("finished", "stopped", "expired", "blocked") and branch_name:
              # Step 1: Get list of files modified in the branch vs main
              modified_files = set()
              try:
                  compare_url = f"https://api.github.com/repos/{repo}/compare/main...{branch_name}"
                  req = urllib.request.Request(compare_url, headers=headers)
                  with urllib.request.urlopen(req, timeout=HTTP_TIMEOUT) as resp:
                      compare_data = json.loads(resp.read())
                  for f in compare_data.get("files", []):
                      modified_files.add(f.get("filename", ""))
                  print(f"Branch {branch_name} modified {len(modified_files)} files vs main:")
                  for mf in sorted(modified_files):
                      print(f"  - {mf}")
              except Exception as e:
                  print(f"  Warning: Could not fetch branch comparison: {e}")
                  print(f"  Falling back to CodeQL-only check")

              # Step 2: Load alert details to get file paths
              alert_files = {}
              try:
                  with open("/tmp/batch_details.json") as f:
                      details = json.load(f)
                  for d in details:
                      alert_files[d.get("number")] = d.get("file", "")
              except Exception:
                  pass

              # Step 3: Classify each alert
              print(f"\nClassifying {total} alerts...")
              for aid in batch_alert_ids:
                  try:
                      url = f"https://api.github.com/repos/{repo}/code-scanning/alerts/{aid}"
                      req = urllib.request.Request(url, headers=headers)
                      with urllib.request.urlopen(req, timeout=HTTP_TIMEOUT) as resp:
                          alert = json.loads(resp.read())
                      state = alert.get("state", "unknown")

                      if state == "fixed":
                          fixed_ids.append(aid)
                          print(f"  Alert #{aid}: FIXED on main (confirmed)")
                      elif state == "dismissed":
                          fixed_ids.append(aid)
                          print(f"  Alert #{aid}: DISMISSED (counts as resolved)")
                      else:
                          # Alert still open on main — check if Devin modified the file
                          alert_file = alert_files.get(aid, "")
                          if not alert_file:
                              loc = alert.get("most_recent_instance", {}).get("location", {})
                              alert_file = loc.get("path", "")
                          if alert_file and alert_file in modified_files:
                              attempted_ids.append(aid)
                              print(f"  Alert #{aid}: ATTEMPTED (file {alert_file} was modified in branch — pending PR merge)")
                          else:
                              unfixable_ids.append(aid)
                              reason = "file not modified by Devin" if alert_file else "file path unknown"
                              print(f"  Alert #{aid}: UNFIXABLE ({reason}, state={state})")
                  except Exception as e:
                      print(f"  Alert #{aid}: ERROR checking ({e}) — marking unfixable")
                      unfixable_ids.append(aid)
                  time.sleep(0.5)
          elif session_status in ("failed", "error", "timeout"):
              print(f"Session {session_status} — all {total} alerts marked unfixable")
              unfixable_ids = list(batch_alert_ids)
          else:
              print(f"Session status={session_status}, branch={branch_name} — all alerts unresolved")
              unfixable_ids = list(batch_alert_ids)

          fixed_count = len(fixed_ids)
          attempted_count = len(attempted_ids)
          failed_count = len(unfixable_ids)

          print(f"\nResults: {fixed_count} confirmed fixed, {attempted_count} attempted (pending merge), {failed_count} unfixable out of {total} total")

          result = {
              "batch_id": batch_id,
              "alert_ids": [str(a) for a in batch_alert_ids],
              "fixed_alert_ids": [str(a) for a in fixed_ids],
              "attempted_alert_ids": [str(a) for a in attempted_ids],
              "unfixable_alert_ids": [str(a) for a in unfixable_ids],
              "session_id": session_id,
              "session_url": session_url,
              "session_status": session_status,
              "pr_number": pr_number,
              "pr_url": pr_url,
              "fixed_count": fixed_count,
              "attempted_count": attempted_count,
              "failed_count": failed_count,
              "branch_name": branch_name
          }

          with open("/tmp/batch_result.json", "w") as f:
              json.dump(result, f, indent=2)

          gh_out = os.environ.get("GITHUB_OUTPUT", "/dev/null")
          with open(gh_out, "a") as f:
              f.write(f"fixed_count={fixed_count}\n")
              f.write(f"attempted_count={attempted_count}\n")
              f.write(f"failed_count={failed_count}\n")
              f.write(f"fixed_alert_ids={','.join(str(a) for a in fixed_ids)}\n")
              f.write(f"attempted_alert_ids={','.join(str(a) for a in attempted_ids)}\n")
              f.write(f"unfixable_alert_ids={','.join(str(a) for a in unfixable_ids)}\n")
              compact = json.dumps(result)
              f.write(f"result_json={compact}\n")

          print(json.dumps(result, indent=2))
          RESULT_EOF

      # ----------------------------------------------------------------
      # STEP 5b: PATCH PR body with classification metadata (Bug #38)
      # This runs AFTER collect-results so we have the full classification.
      # The PR body created in Step 4 is a template; this step appends
      # machine-readable metadata (JSON in HTML comment) for the orchestrator
      # to correlate which alerts were fixed/attempted/unfixable per PR.
      # ----------------------------------------------------------------
      - name: Update PR with classification metadata
        if: always() && steps.create-pr.outputs.pr_created == 'true'
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
          REPO: ${{ github.repository }}
          PR_NUMBER: ${{ steps.create-pr.outputs.pr_number }}
        run: |
          FIXED="${{ steps.collect-results.outputs.fixed_alert_ids }}"
          ATTEMPTED="${{ steps.collect-results.outputs.attempted_alert_ids }}"
          UNFIXABLE="${{ steps.collect-results.outputs.unfixable_alert_ids }}"
          FIXED_COUNT="${{ steps.collect-results.outputs.fixed_count }}"
          ATTEMPTED_COUNT="${{ steps.collect-results.outputs.attempted_count }}"
          FAILED_COUNT="${{ steps.collect-results.outputs.failed_count }}"

          CURRENT_BODY=$(curl -s -L \
            -H "Authorization: token $GH_PAT" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/repos/$REPO/pulls/$PR_NUMBER" | jq -r '.body // ""')

          METADATA_BLOCK="<!-- batch-classification-metadata
          {\"batch_id\":\"$BATCH_ID\",\"fixed_alert_ids\":\"$FIXED\",\"attempted_alert_ids\":\"$ATTEMPTED\",\"unfixable_alert_ids\":\"$UNFIXABLE\",\"fixed_count\":$FIXED_COUNT,\"attempted_count\":$ATTEMPTED_COUNT,\"unfixable_count\":$FAILED_COUNT,\"session_id\":\"${{ steps.create-session.outputs.session_id }}\",\"run_id\":\"${{ github.run_id }}\"}
          -->"

          CLASSIFICATION_TABLE="\n\n---\n### Alert Classification Summary\n| Category | Count | Alert IDs |\n|----------|-------|-----------|\n| Fixed (confirmed) | ${FIXED_COUNT:-0} | ${FIXED:-none} |\n| Attempted (pending merge) | ${ATTEMPTED_COUNT:-0} | ${ATTEMPTED:-none} |\n| Unfixable (human review) | ${FAILED_COUNT:-0} | ${UNFIXABLE:-none} |"

          NEW_BODY="${CURRENT_BODY}${CLASSIFICATION_TABLE}\n\n${METADATA_BLOCK}"
          BODY_JSON=$(echo -e "$NEW_BODY" | python3 -c "import sys,json; print(json.dumps(sys.stdin.read()))")

          PATCH_RESP=$(curl -s -L -w "\n%{http_code}" \
            -X PATCH \
            -H "Authorization: token $GH_PAT" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/repos/$REPO/pulls/$PR_NUMBER" \
            -d "{\"body\": $BODY_JSON}")
          PATCH_HTTP=$(echo "$PATCH_RESP" | tail -1)
          if [ "$PATCH_HTTP" = "200" ]; then
            echo "PR #$PR_NUMBER body updated with classification metadata"
          else
            echo "::warning::Failed to update PR body with metadata (HTTP $PATCH_HTTP)"
          fi

      - name: Upload batch result artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: batch-${{ env.BATCH_ID }}-result
          path: /tmp/batch_result.json
          retention-days: 30

      - name: Summary
        if: always()
        run: |
          echo "## Batch #$BATCH_ID Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Alerts**: $(cat /tmp/batch_details.json 2>/dev/null | jq 'length' 2>/dev/null || echo 0)" >> $GITHUB_STEP_SUMMARY
          echo "- **Session**: ${{ steps.create-session.outputs.session_url }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ steps.poll-session.outputs.status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **PR**: ${{ steps.create-pr.outputs.pr_url }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Fixed (confirmed)**: ${{ steps.collect-results.outputs.fixed_count }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Attempted (pending PR merge)**: ${{ steps.collect-results.outputs.attempted_count }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Unfixable (needs human review)**: ${{ steps.collect-results.outputs.failed_count }}" >> $GITHUB_STEP_SUMMARY
          if [ -n "${{ steps.collect-results.outputs.unfixable_alert_ids }}" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Alerts Requiring Human Review" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            IFS=',' read -ra UNFIXABLE <<< "${{ steps.collect-results.outputs.unfixable_alert_ids }}"
            for aid in "${UNFIXABLE[@]}"; do
              if [ -n "$aid" ]; then
                echo "- [ ] Alert [#${aid}](https://github.com/${{ github.repository }}/security/code-scanning/${aid})" >> $GITHUB_STEP_SUMMARY
              fi
            done
          fi
          if [ -n "${{ steps.collect-results.outputs.attempted_alert_ids }}" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Alerts Pending PR Merge Verification" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "_These alerts' files were modified by Devin. They will be confirmed fixed after the PR is merged and CodeQL re-runs._" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            IFS=',' read -ra ATTEMPTED <<< "${{ steps.collect-results.outputs.attempted_alert_ids }}"
            for aid in "${ATTEMPTED[@]}"; do
              if [ -n "$aid" ]; then
                echo "- Alert [#${aid}](https://github.com/${{ github.repository }}/security/code-scanning/${aid})" >> $GITHUB_STEP_SUMMARY
              fi
            done
          fi
